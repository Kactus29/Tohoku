{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e52fecd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb810597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05bf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PyTorch version', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import DiceLoss, FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43967ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import init_confmat_sums, init_auc_buffers\n",
    "from helper_functions import update_confmat_sums, update_auc_buffers\n",
    "from helper_functions import compute_scalar_metrics_from_confmat, compute_mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd8cec",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f693c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dir = Path(\"Models/My_UNet_alpha_v1\")\n",
    "\n",
    "x = int(input(\"Choose model to load (0: dice, 1: loss, 2: epoch250): \"))\n",
    "chose = [\"dice\", \"loss\", \"epoch250\"][x]\n",
    "base_model_path = base_model_dir / f\"{chose}_best_model_full.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(base_model_path, map_location=device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f0a3d",
   "metadata": {},
   "source": [
    "# Create subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e15471",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a295975",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_dir = base_model_dir / f\"fine-tune_{fine_tune_index}\"\n",
    "fine_tune_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Fine-tuning results will be saved in: {fine_tune_dir}\")\n",
    "\n",
    "curves_dir = fine_tune_dir / \"curves\"\n",
    "pred_dir = fine_tune_dir / \"predictions\"\n",
    "curves_dir.mkdir(exist_ok=True)\n",
    "pred_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a688b",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2cd71",
   "metadata": {},
   "source": [
    "#### Directories for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ac0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = Path().cwd().parent\n",
    "data_root = parent / 'try_1'\n",
    "\n",
    "train_images_dir = data_root / 'train' / 'images'\n",
    "train_masks_dir = data_root / 'train' / 'masks'\n",
    "\n",
    "val_images_dir = data_root / 'val' / 'images'\n",
    "val_masks_dir = data_root / 'val' / 'masks'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d88eb29",
   "metadata": {},
   "source": [
    "#### General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64281933",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 768\n",
    "IMG_WIDTH = 768\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 50\n",
    "print('Number of epochs:', EPOCHS)\n",
    "\n",
    "LR = 0.001\n",
    "print('Learning rate:', LR)\n",
    "\n",
    "\"\"\"\n",
    "0 : background (black)\n",
    "1 : arteries (white)\n",
    "2 : veins (gray)\n",
    "\"\"\"\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "COLOR_TO_LABEL = {\n",
    "    (0,0,0): 0,\n",
    "    (255,255,255): 1,\n",
    "    (128,128,128): 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78700d",
   "metadata": {},
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ca97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAVIRDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, img_size=(IMG_HEIGHT, IMG_WIDTH), transforms=None):\n",
    "        self.img_paths = sorted(list(Path(img_dir).glob('*.png')))\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.img_size = img_size\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_p = self.img_paths[idx]\n",
    "        mask_p = self.mask_dir / img_p.name\n",
    "        img = Image.open(img_p).convert('RGB').resize(self.img_size, Image.BILINEAR)\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        img = np.transpose(img, (2,0,1))  # C,H,W\n",
    "        img_t = torch.from_numpy(img).float()\n",
    "        # load mask and map colors to labels\n",
    "        m = Image.open(mask_p).convert('RGB').resize(self.img_size, Image.NEAREST)\n",
    "        m_arr = np.array(m, dtype=np.uint8)\n",
    "        label = np.zeros((self.img_size[1], self.img_size[0]), dtype=np.uint8)\n",
    "        for color, lab in COLOR_TO_LABEL.items():\n",
    "            mask = np.all(m_arr == np.array(color, dtype=np.uint8), axis=-1)\n",
    "            label[mask] = lab\n",
    "        label_t = torch.from_numpy(label).long()  # H,W\n",
    "        return img_t, label_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RAVIRDataset(train_images_dir, train_masks_dir, (IMG_WIDTH, IMG_HEIGHT))\n",
    "val_ds = RAVIRDataset(val_images_dir, val_masks_dir, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af12359",
   "metadata": {},
   "source": [
    "# Function parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fc988",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29a96a",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eadb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(outputs, targets, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    outputs: logits (N, C, H, W)\n",
    "    targets: labels (N, H, W)\n",
    "    \"\"\"\n",
    "    # Probabilit√©s\n",
    "    probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "    N, C, H, W = probs.shape\n",
    "\n",
    "    # One-hot du masque ‚Üí shape (N, C, H, W)\n",
    "    targets_onehot = F.one_hot(targets, num_classes=C).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    # On ignore la classe 0 (background)\n",
    "    probs = probs[:, 1:, :, :]          # (N, C-1, H, W)\n",
    "    targets_onehot = targets_onehot[:, 1:, :, :]  # (N, C-1, H, W)\n",
    "\n",
    "    # Dice par classe\n",
    "    intersection = torch.sum(probs * targets_onehot, dim=(0, 2, 3))\n",
    "    cardinality  = torch.sum(probs + targets_onehot, dim=(0, 2, 3))\n",
    "\n",
    "    dice_per_class = (2 * intersection + epsilon) / (cardinality + epsilon)\n",
    "\n",
    "    # Loss = 1 - moyenne des dice des classes artery + vein\n",
    "    return 1 - dice_per_class.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4559ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = [0.872, 0.054, 0.073]\n",
    "inverse_percentage = [round((1/p),2) for p in percentage]\n",
    "print(inverse_percentage)\n",
    "\n",
    "weights = torch.tensor(inverse_percentage).to(device)\n",
    "CE_loss = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacce6b2",
   "metadata": {},
   "source": [
    "##### Alpha functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944536b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_linear(epoch, total_epochs, start=0.9, end=0.1):\n",
    "    \"\"\"Œ±(t) linearly decrease from start to end\"\"\"\n",
    "    return start - (start - end) * (epoch / (total_epochs - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7350d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_exponential(epoch, total_epochs, start=0.9, end=0.1, k=5) :\n",
    "\t\"\"\"Œ±(t) decreases fastly at first, then stabilises\"\"\"\n",
    "\treturn end + (start-end)*np.exp(-k * epoch / (total_epochs-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9670f",
   "metadata": {},
   "source": [
    "#### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LR*10, \n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a97af",
   "metadata": {},
   "source": [
    "# Fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a79970",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3\n",
    "BACKGROUND_IDX = 0\n",
    "VESSEL_CLASSES = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4066dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_val_dice = -float(\"inf\")\n",
    "\n",
    "save_dir = fine_tune_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = {\n",
    "    \"loss\": [],\n",
    "    \"accuracy\":   [],\n",
    "    \"dice\":       [],\n",
    "    \"iou\":        [],\n",
    "    \"precision\":  [],\n",
    "    \"recall\":     [],\n",
    "    \"sensitivity\":[],\n",
    "    \"specificity\":[],\n",
    "    \"auc\":        [],\n",
    "    \"lr\":         [],\n",
    "    \"alpha\":      []\n",
    "}\n",
    "\n",
    "val_history = {\n",
    "    \"loss\": [],\n",
    "    \"accuracy\":   [],\n",
    "    \"dice\":       [],\n",
    "    \"iou\":        [],\n",
    "    \"precision\":  [],\n",
    "    \"recall\":     [],\n",
    "    \"sensitivity\":[],\n",
    "    \"specificity\":[],\n",
    "    \"auc\":        []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ec54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#        LEARNING\n",
    "# =========================\n",
    "\n",
    "for epoch in range(EPOCHS) :\n",
    "\n",
    "    # =========================\n",
    "    #        TRAIN\n",
    "    # =========================\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    runing_loss = 0.0\n",
    "    conf_sums = init_confmat_sums()\n",
    "    auc_buf = init_auc_buffers()\n",
    "\n",
    "    for imgs, masks in train_loader :\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        alpha = alpha_exponential(epoch, EPOCHS, start=0.9, end=0.1, k=5)\n",
    "        loss = alpha * CE_loss(outputs, masks) + (1-alpha) * dice_loss(outputs, masks)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        runing_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        update_confmat_sums(conf_sums, preds, masks, NUM_CLASSES)\n",
    "        update_auc_buffers(auc_buf, outputs, masks)\n",
    "    \n",
    "    train_loss = runing_loss / len(train_ds)\n",
    "    train_metrics = compute_scalar_metrics_from_confmat(conf_sums, VESSEL_CLASSES)\n",
    "    train_auc = compute_mean_auc(auc_buf)\n",
    "\n",
    "    train_history[\"loss\"].append(train_loss)\n",
    "    train_history[\"accuracy\"].append(train_metrics[\"accuracy\"])\n",
    "    train_history[\"dice\"].append(train_metrics[\"dice\"])\n",
    "    train_history[\"iou\"].append(train_metrics[\"iou\"])\n",
    "    train_history[\"precision\"].append(train_metrics[\"precision\"])\n",
    "    train_history[\"recall\"].append(train_metrics[\"recall\"])\n",
    "    train_history[\"specificity\"].append(train_metrics[\"specificity\"])\n",
    "    train_history[\"auc\"].append(train_auc)\n",
    "    train_history[\"lr\"].append(scheduler.get_last_lr()[0])\n",
    "    train_history[\"alpha\"].append(alpha)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # =========================\n",
    "    #       VALIDATION\n",
    "    # =========================\n",
    "    model.eval()\n",
    "\n",
    "    val_runing_loss = 0.0\n",
    "    conf_sums_val = init_confmat_sums()\n",
    "    auc_buf_val   = init_auc_buffers()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs  = imgs.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            alpha = alpha_exponential(epoch, EPOCHS, start=0.9, end=0.1, k=5)\n",
    "            loss = alpha * CE_loss(outputs, masks) + (1-alpha) * dice_loss(outputs, masks)\n",
    "\n",
    "            val_runing_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            update_confmat_sums(conf_sums_val, preds, masks, NUM_CLASSES)\n",
    "            update_auc_buffers(auc_buf_val, outputs, masks)\n",
    "\n",
    "    val_loss = val_runing_loss / len(val_ds)\n",
    "    val_metrics = compute_scalar_metrics_from_confmat(conf_sums_val, VESSEL_CLASSES)\n",
    "    val_auc = compute_mean_auc(auc_buf_val)\n",
    "\n",
    "    val_history[\"loss\"].append(val_loss)\n",
    "    val_history[\"accuracy\"].append(val_metrics[\"accuracy\"])\n",
    "    val_history[\"dice\"].append(val_metrics[\"dice\"])\n",
    "    val_history[\"iou\"].append(val_metrics[\"iou\"])\n",
    "    val_history[\"precision\"].append(val_metrics[\"precision\"])\n",
    "    val_history[\"recall\"].append(val_metrics[\"recall\"])\n",
    "    val_history[\"specificity\"].append(val_metrics[\"specificity\"])\n",
    "    val_history[\"auc\"].append(val_auc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # =========================\n",
    "    #           LOGS\n",
    "    # =========================\n",
    "    print('-'*30)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Dice: {train_metrics['dice']:.4f} | IoU: {train_metrics['iou']:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Dice: {val_metrics['dice']:.4f} | IoU: {val_metrics['iou']:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # =========================\n",
    "    #     SAVE BEST MODEL\n",
    "    # =========================\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), str(save_dir / \"loss_best_model_state_dict.pth\"))\n",
    "        torch.save(model, str(save_dir / \"loss_best_model_full.pth\"))\n",
    "        print(f\"‚úÖ Nouveau meilleur mod√®le loss sauvegard√©\")\n",
    "    \n",
    "    val_dice = val_metrics[\"dice\"]\n",
    "    if val_dice > best_val_dice :\n",
    "        best_val_dice = val_dice\n",
    "        torch.save(model.state_dict(), str(save_dir / \"dice_best_model_state_dict.pth\"))\n",
    "        torch.save(model, str(save_dir / \"dice_best_model_full.pth\"))\n",
    "        print(f\"‚úÖ Nouveau meilleur mod√®le dice sauvegard√©\")\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "#     SAVE LAST MODEL\n",
    "# =========================\n",
    "torch.save(model.state_dict(), str(save_dir / f\"epoch{EPOCHS}_model_state_dict.pth\"))\n",
    "torch.save(model, str(save_dir / f\"epoch{EPOCHS}_model_full.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af543fa",
   "metadata": {},
   "source": [
    "# Validation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a851b9",
   "metadata": {},
   "source": [
    "#### Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef19f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(save_dir / f\"{x}_best_model_full.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60bf74",
   "metadata": {},
   "source": [
    "#### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_correct = 0\n",
    "total_pixels = 0\n",
    "\n",
    "# üìÅ Dossier pour sauvegarder les pr√©dictions\n",
    "pred_dir = save_dir / \"predictions\"\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    img_index = 0  # compteur global des images\n",
    "\n",
    "    for imgs, masks in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        preds = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "\n",
    "        # Boucle sur chaque image du batch\n",
    "        for i in range(len(imgs)):\n",
    "            pred = preds[i]\n",
    "            mask = masks[i]\n",
    "\n",
    "            # ===== Calcul de l‚Äôaccuracy de cette image =====\n",
    "            correct_pixels = (pred == mask).sum().item()\n",
    "            total_pixels_img = mask.numel()\n",
    "            acc_img = correct_pixels / total_pixels_img\n",
    "\n",
    "            print(f\"üñºÔ∏è Image {img_index+1} ‚Äî Accuracy : {acc_img:.4f}\")\n",
    "\n",
    "            # ===== Cr√©ation de la figure =====\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "            ax[0].imshow(imgs[i].cpu().permute(1, 2, 0))\n",
    "            ax[0].set_title(\"Original picture\")\n",
    "            ax[1].imshow(mask.cpu(), cmap=\"gray\")\n",
    "            ax[1].set_title(\"Real mask\")\n",
    "            ax[2].imshow(pred.cpu(), cmap=\"gray\")\n",
    "            ax[2].set_title(\"Predicted mask\")\n",
    "            for a in ax:\n",
    "                a.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # üìå Sauvegarde dans Models/<model_name>/predictions/\n",
    "            save_path = pred_dir / f\"val_img_{img_index:03d}.png\"\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "\n",
    "            # ‚úÖ Affichage imm√©diat dans notebook\n",
    "            plt.show()\n",
    "\n",
    "            # ===== Accumulateur global =====\n",
    "            total_correct += correct_pixels\n",
    "            total_pixels += total_pixels_img\n",
    "            img_index += 1\n",
    "\n",
    "# ===== Accuracy globale =====\n",
    "val_acc = total_correct / total_pixels\n",
    "print(f\"\\n‚úÖ Accuracy moyenne sur le jeu de validation : {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c2f50",
   "metadata": {},
   "source": [
    "#### Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8321f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(train_history, val_history, key, title=None, mark_best_on=\"val_loss\", save_folder=curves_dir):\n",
    "    \"\"\"\n",
    "    key:        nom de la m√©trique dans les dicts (ex: \"loss\", \"dice\", \"auc\")\n",
    "    mark_best_on:\n",
    "        - \"val_loss\" ‚Üí marquer l'epoch o√π val_loss est minimal\n",
    "        - \"val_<key>\" ‚Üí marquer la meilleure valeur de cette m√©trique (max)\n",
    "    \"\"\"\n",
    "\n",
    "    train = train_history.get(key, [])\n",
    "    val   = val_history.get(key, [])\n",
    "\n",
    "    if len(val) == 0:\n",
    "        print(f\"‚ö†Ô∏è Impossible de tracer '{key}' (pas de valeurs validation trouv√©es)\")\n",
    "        return\n",
    "\n",
    "    epochs = range(1, len(val)+1)\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(epochs, train, label=f\"Train {key}\", linewidth=2)\n",
    "    plt.plot(epochs, val,   label=f\"Val {key}\", linewidth=2)\n",
    "\n",
    "    # ========= Marqueur du \"best\" =========\n",
    "    if mark_best_on == \"val_loss\" and \"loss\" in val_history:\n",
    "        best_e = int(np.argmin(val_history[\"loss\"])) + 1\n",
    "        best_v = val[best_e-1]\n",
    "        plt.scatter([best_e], [best_v], s=80, marker=\"o\", color=\"red\", zorder=3,\n",
    "                    label=f\"best @ epoch {best_e}\")\n",
    "    elif mark_best_on == f\"val_{key}\" and len(val) > 0:\n",
    "        best_e = int(np.nanargmax(val)) + 1\n",
    "        best_v = val[best_e-1]\n",
    "        plt.scatter([best_e], [best_v], s=80, marker=\"o\", color=\"red\", zorder=3,\n",
    "                    label=f\"best @ epoch {best_e}\")\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(key)\n",
    "    plt.title(title or f\"{key} (train vs val)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # ========= SAVE =========\n",
    "    save_path = save_folder / f\"{key}.png\"\n",
    "    plt.savefig(save_path, dpi=200, bbox_inches=\"tight\")\n",
    "    print(f\"üíæ Courbe sauvegard√©e : {save_path}\")\n",
    "\n",
    "    plt.show()   # continue √† afficher\n",
    "\n",
    "\n",
    "# ======== TRA√áAGE ========\n",
    "\n",
    "plot_metric(train_history, val_history, \"loss\", title=\"Loss curves\", mark_best_on=\"val_loss\")\n",
    "plot_metric(train_history, val_history, \"dice\", title=\"Dice (artery+vein avg)\", mark_best_on=\"val_dice\")\n",
    "plot_metric(train_history, val_history, \"auc\",  title=\"AUC (artery+vein avg)\",  mark_best_on=\"val_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6261b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = train_history.get(\"alpha\", [])\n",
    "lr_values = train_history.get(\"lr\", [])\n",
    "epochs = np.arange(1, len(alpha_values) + 1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   COURBE ALPHA(t)\n",
    "# =========================\n",
    "fig_alpha, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(epochs, alpha_values, color=\"#1f77b4\", linewidth=2)\n",
    "ax.set_title(\"Evolution of Œ± in Loss = Œ± * CE + (1-Œ±)*DiceLoss\")\n",
    "ax.set_xlabel(\"Epoch\", fontsize=11)\n",
    "ax.set_ylabel(\"Œ± value\", fontsize=11)\n",
    "ax.grid(alpha=0.4)\n",
    "ax.legend([\"Œ±(t) schedule\"], loc=\"best\")\n",
    "plt.tight_layout()\n",
    "\n",
    "alpha_path = curves_dir / \"alpha_curve.png\"\n",
    "plt.savefig(alpha_path, dpi=200, bbox_inches='tight')\n",
    "print(f\"‚úÖ Courbe Œ±(t) sauvegard√©e dans : {alpha_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   COURBE LEARNING RATE\n",
    "# =========================\n",
    "fig_lr, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(epochs, lr_values, color=\"#ff7f0e\", linewidth=2)\n",
    "ax.set_title(\"Learning Rate Schedule\")\n",
    "ax.set_xlabel(\"Epoch\", fontsize=11)\n",
    "ax.set_ylabel(\"Learning rate\", fontsize=11)\n",
    "ax.grid(alpha=0.4)\n",
    "ax.legend([\"lr(t)\"], loc=\"best\")\n",
    "plt.tight_layout()\n",
    "\n",
    "lr_path = curves_dir / \"lr_curve.png\"\n",
    "plt.savefig(lr_path, dpi=200, bbox_inches='tight')\n",
    "print(f\"‚úÖ Courbe learning rate sauvegard√©e dans : {lr_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6603c",
   "metadata": {},
   "source": [
    "#### Summary of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78602b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#   CONFIG CLASSES\n",
    "# =========================\n",
    "ARTERY_CLASS = 1\n",
    "VEIN_CLASS   = 2\n",
    "VESSEL_CLASSES = [ARTERY_CLASS, VEIN_CLASS]\n",
    "assert NUM_CLASSES >= 3, \"NUM_CLASSES doit inclure background + artery + vein\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "#  UTILS: m√©triques par classe\n",
    "# =========================\n",
    "def compute_per_class_metrics_from_confmat(sums, c):\n",
    "    TP, FP, FN, TN = sums[\"TP\"][c], sums[\"FP\"][c], sums[\"FN\"][c], sums[\"TN\"][c]\n",
    "    eps = 1e-7\n",
    "\n",
    "    acc  = (TP + TN) / max(TP + TN + FP + FN, eps)\n",
    "    prec = TP / max(TP + FP, eps)\n",
    "    rec  = TP / max(TP + FN, eps)\n",
    "    spec = TN / max(TN + FP, eps)\n",
    "    dice = (2 * TP) / max(2 * TP + FP + FN, eps)\n",
    "    iou  = TP / max(TP + FP + FN, eps)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\":   float(acc),\n",
    "        \"precision\":  float(prec),\n",
    "        \"recall\":     float(rec),      # Sensitivity\n",
    "        \"specificity\":float(spec),\n",
    "        \"dice\":       float(dice),\n",
    "        \"iou\":        float(iou),\n",
    "    }\n",
    "\n",
    "def compute_auc_for_class(buffers, c):\n",
    "    pack = buffers.get(c, None)\n",
    "    if pack is None or len(pack[\"y_true\"]) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    y_true  = np.concatenate(pack[\"y_true\"])\n",
    "    y_score = np.concatenate(pack[\"y_score\"])\n",
    "\n",
    "    pos = (y_true == 1).sum()\n",
    "    neg = (y_true == 0).sum()\n",
    "    if pos == 0 or neg == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    try:\n",
    "        return float(roc_auc_score(y_true, y_score))\n",
    "    except:\n",
    "        return float(\"nan\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   √âVALUATION\n",
    "# =========================\n",
    "model.eval()\n",
    "conf_sums_val = init_confmat_sums(num_classes=NUM_CLASSES)\n",
    "auc_buf_val   = init_auc_buffers(include_classes=VESSEL_CLASSES)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, masks in val_loader:\n",
    "        imgs  = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        update_confmat_sums(conf_sums_val, preds, masks, NUM_CLASSES)\n",
    "        update_auc_buffers(auc_buf_val, outputs, masks)\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   M√âTRIQUES PAR CLASSE\n",
    "# =========================\n",
    "results = {}\n",
    "\n",
    "for cls, name in zip(VESSEL_CLASSES, [\"Artery\", \"Vein\"]):\n",
    "    m = compute_per_class_metrics_from_confmat(conf_sums_val, cls)\n",
    "    m[\"auc\"] = compute_auc_for_class(auc_buf_val, cls)\n",
    "    results[name] = m\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   MOYENNES ARTERY + VEIN\n",
    "# =========================\n",
    "avg_metrics = {metric: np.nanmean([results[\"Artery\"][metric], results[\"Vein\"][metric]])\n",
    "               for metric in results[\"Artery\"].keys()}\n",
    "\n",
    "results[\"Average (A+V)\"] = avg_metrics\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   AFFICHAGE TABLEAU (4 d√©cimales)\n",
    "# =========================\n",
    "df = pd.DataFrame(results).T\n",
    "df = df.round(4)  # <= Arrondi propre √† 4 d√©cimales\n",
    "\n",
    "print(\"\\n=== R√©sultats de validation ===\\n\")\n",
    "display(df.style.format(\"{:.4f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05450a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#   CONFIG CLASSES\n",
    "# =========================\n",
    "ARTERY_CLASS = 1\n",
    "VEIN_CLASS   = 2\n",
    "VESSEL_CLASSES = [ARTERY_CLASS, VEIN_CLASS]\n",
    "assert NUM_CLASSES >= 3, \"NUM_CLASSES must include background + artery + vein\"\n",
    "\n",
    "# =========================\n",
    "#   PER-IMAGE METRIC HELPERS\n",
    "# =========================\n",
    "def dice_per_image(pred, target, cls):\n",
    "    eps = 1e-7\n",
    "    p = (pred == cls).float()\n",
    "    t = (target == cls).float()\n",
    "    inter = (p * t).sum()\n",
    "    denom = p.sum() + t.sum()\n",
    "    return float((2.0 * inter) / (denom + eps))\n",
    "\n",
    "def iou_per_image(pred, target, cls):\n",
    "    eps = 1e-7\n",
    "    p = (pred == cls)\n",
    "    t = (target == cls)\n",
    "    inter = (p & t).sum().item()\n",
    "    union = (p | t).sum().item()\n",
    "    return float(inter / (union + eps))\n",
    "\n",
    "def auc_per_image_from_logits(logits, target, cls):\n",
    "    # logits: (C,H,W) for a single image\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "    y_score = probs[cls].reshape(-1).cpu().numpy()\n",
    "    y_true  = (target == cls).reshape(-1).cpu().numpy().astype(np.uint8)\n",
    "    pos = (y_true == 1).sum()\n",
    "    neg = (y_true == 0).sum()\n",
    "    if pos == 0 or neg == 0:\n",
    "        return float(\"nan\")\n",
    "    try:\n",
    "        return float(roc_auc_score(y_true, y_score))\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "# =========================\n",
    "#   COLLECT PER-IMAGE METRICS\n",
    "# =========================\n",
    "model.eval()\n",
    "\n",
    "artery_dice_list, vein_dice_list, avg_dice_list = [], [], []\n",
    "artery_iou_list,  vein_iou_list,  avg_iou_list  = [], [], []\n",
    "artery_auc_list,  vein_auc_list,  avg_auc_list  = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, masks in val_loader:\n",
    "        imgs  = imgs.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        logits = model(imgs)          # (N,C,H,W)\n",
    "        preds  = logits.argmax(dim=1) # (N,H,W)\n",
    "\n",
    "        for i in range(imgs.size(0)):\n",
    "            p   = preds[i]\n",
    "            gt  = masks[i]\n",
    "            log = logits[i]\n",
    "\n",
    "            # Dice\n",
    "            a_d = dice_per_image(p, gt, ARTERY_CLASS)\n",
    "            v_d = dice_per_image(p, gt, VEIN_CLASS)\n",
    "            artery_dice_list.append(a_d)\n",
    "            vein_dice_list.append(v_d)\n",
    "            avg_dice_list.append(np.nanmean([a_d, v_d]))\n",
    "\n",
    "            # IoU\n",
    "            a_i = iou_per_image(p, gt, ARTERY_CLASS)\n",
    "            v_i = iou_per_image(p, gt, VEIN_CLASS)\n",
    "            artery_iou_list.append(a_i)\n",
    "            vein_iou_list.append(v_i)\n",
    "            avg_iou_list.append(np.nanmean([a_i, v_i]))\n",
    "\n",
    "            # AUC\n",
    "            a_auc = auc_per_image_from_logits(log, gt, ARTERY_CLASS)\n",
    "            v_auc = auc_per_image_from_logits(log, gt, VEIN_CLASS)\n",
    "            artery_auc_list.append(a_auc)\n",
    "            vein_auc_list.append(v_auc)\n",
    "            avg_auc_list.append(np.nanmean([a_auc, v_auc]))\n",
    "\n",
    "# =========================\n",
    "#   BAR PLOTS (3 rows √ó 3 cols)\n",
    "#   One bar per image; red dashed = mean\n",
    "# =========================\n",
    "def plot_bars_one_metric(ax, values, title):\n",
    "    values = np.array(values, dtype=float)\n",
    "    n = len(values)\n",
    "    x = np.arange(1, n+1)\n",
    "\n",
    "    ax.bar(x, values, color=\"#1f77b4\", edgecolor=\"black\", alpha=0.9)\n",
    "\n",
    "    m = np.nanmean(values)\n",
    "    ax.axhline(m, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"mean = {m:.3f}\")\n",
    "\n",
    "    ax.set_ylim(0, 1)            # metrics in [0,1]\n",
    "    ax.set_xlim(0.5, n + 0.5)\n",
    "    ax.set_xlabel(\"Validation image index\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(title)\n",
    "    # lighten x ticks if many images\n",
    "    if n > 30:\n",
    "        ax.set_xticks(np.linspace(1, n, 10, dtype=int))\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 12), constrained_layout=True)\n",
    "\n",
    "# Row 1: Dice\n",
    "plot_bars_one_metric(axes[0,0], artery_dice_list, \"Dice ‚Äì Artery\")\n",
    "plot_bars_one_metric(axes[0,1], vein_dice_list,   \"Dice ‚Äì Vein\")\n",
    "plot_bars_one_metric(axes[0,2], avg_dice_list,    \"Dice ‚Äì Average (A+V)\")\n",
    "\n",
    "# Row 2: IoU\n",
    "plot_bars_one_metric(axes[1,0], artery_iou_list, \"IoU ‚Äì Artery\")\n",
    "plot_bars_one_metric(axes[1,1], vein_iou_list,   \"IoU ‚Äì Vein\")\n",
    "plot_bars_one_metric(axes[1,2], avg_iou_list,    \"IoU ‚Äì Average (A+V)\")\n",
    "\n",
    "# Row 3: AUC\n",
    "plot_bars_one_metric(axes[2,0], artery_auc_list, \"AUC ‚Äì Artery\")\n",
    "plot_bars_one_metric(axes[2,1], vein_auc_list,   \"AUC ‚Äì Vein\")\n",
    "plot_bars_one_metric(axes[2,2], avg_auc_list,    \"AUC ‚Äì Average (A+V)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
