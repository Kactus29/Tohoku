{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1665106f",
   "metadata": {},
   "source": [
    "# 1) Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fcba7a",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d28031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dde6b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.9.1+cu128\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89344d",
   "metadata": {},
   "source": [
    "#### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70b2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011117b",
   "metadata": {},
   "source": [
    "#### Monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2024b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "print(\"MONAI version:\", monai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032ffc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet as MonaiUNet\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandZoomd,\n",
    "    RandAffined,\n",
    "    RandGaussianNoised,\n",
    "    RandShiftIntensityd,\n",
    "    RandScaleIntensityd,\n",
    "    EnsureTyped,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c8842",
   "metadata": {},
   "source": [
    "# 2) Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882f3f4",
   "metadata": {},
   "source": [
    "#### 2.1) Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eabf5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_root = Path(\"/home/usrs/hnoel/DRIVE\")\n",
    "\n",
    "# TRAIN = 20 images (21–40)\n",
    "train_images_dir = drive_root / \"training\" / \"images\"\n",
    "train_manual_dir = drive_root / \"training\" / \"1st_manual\"   # 21_manual1.gif, ...\n",
    "train_fov_dir    = drive_root / \"training\" / \"masks\"        # 21_training_mask.tif, ...\n",
    "\n",
    "# TEST = 20 images (01–20)\n",
    "test_images_dir  = drive_root / \"test\" / \"images\"\n",
    "test_manual_dir  = drive_root / \"test\" / \"1st_manual\"       # 01_manual1.gif, ...\n",
    "test_fov_dir     = drive_root / \"test\" / \"masks\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a576d5",
   "metadata": {},
   "source": [
    "#### 2.2) Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68a21ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image sizes\n",
    "IMG_HEIGHT = 584\n",
    "IMG_WIDTH  = 565\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 6\n",
    "\n",
    "# Number of epochs\n",
    "EPOCHS = 200\n",
    "\n",
    "# Learning rate\n",
    "LR = 1e-3\n",
    "\n",
    "# Classes\n",
    "NUM_CLASSES = 2\n",
    "BACKGROUND_IDX = 0\n",
    "VESSEL_CLASS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb17232e",
   "metadata": {},
   "source": [
    "#### 2.3) Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02efa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed fixed to 42\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Python\n",
    "random.seed(SEED)\n",
    "\n",
    "# NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Monai\n",
    "set_determinism(seed=SEED)\n",
    "\n",
    "print(f\"Seed fixed to {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990917c",
   "metadata": {},
   "source": [
    "#### 2.4) Save directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ad7e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"UNet_DRIVE_v1\"\n",
    "\n",
    "# Courbes, JSON, figures, etc.\n",
    "data_dir = Path(\"/home/usrs/hnoel/Tohoku/Monai/UNet\") / model_name\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Poids de modèles\n",
    "models_dir = Path(\"/home/usrs/hnoel/MODELS/UNet\") / model_name\n",
    "models_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad91b9",
   "metadata": {},
   "source": [
    "# 3) DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d49fc",
   "metadata": {},
   "source": [
    "#### 3.1) Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06652521",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    # --- Géométriques (image + label + fov) ---\n",
    "    RandFlipd(keys=[\"image\", \"label\", \"fov\"], prob=0.6, spatial_axis=0),\n",
    "    RandFlipd(keys=[\"image\", \"label\", \"fov\"], prob=0.5, spatial_axis=1),\n",
    "    RandRotate90d(keys=[\"image\", \"label\", \"fov\"], prob=0.4, max_k=3),\n",
    "\n",
    "    RandZoomd(\n",
    "        keys=[\"image\", \"label\", \"fov\"],\n",
    "        prob=0.3,\n",
    "        min_zoom=0.9,\n",
    "        max_zoom=1.1,\n",
    "        mode=(\"bilinear\", \"nearest\", \"nearest\"),  # image / label / fov\n",
    "        keep_size=True,\n",
    "    ),\n",
    "\n",
    "    RandAffined(\n",
    "        keys=[\"image\", \"label\", \"fov\"],\n",
    "        prob=0.2,\n",
    "        rotate_range=(0.15, 0.15),      # ~8.5°\n",
    "        shear_range=(0.05, 0.05),\n",
    "        translate_range=(8, 8),\n",
    "        scale_range=(0.05, 0.05),\n",
    "        mode=(\"bilinear\", \"nearest\", \"nearest\"),\n",
    "        padding_mode=\"zeros\",\n",
    "    ),\n",
    "\n",
    "    # --- Intensité (image seule) ---\n",
    "    RandGaussianNoised(keys=[\"image\"], prob=0.1, std=0.01),\n",
    "    RandShiftIntensityd(keys=[\"image\"], prob=0.1, offsets=0.1),\n",
    "    RandScaleIntensityd(keys=[\"image\"], prob=0.1, factors=0.1),\n",
    "\n",
    "    # S'assure que tout est bien en tensors PyTorch\n",
    "    EnsureTyped(keys=[\"image\", \"label\", \"fov\"]),\n",
    "])\n",
    "\n",
    "# Pas d'augmentation sur la validation\n",
    "val_transforms = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0c4b2",
   "metadata": {},
   "source": [
    "#### 3.2) Create the class fot the DRIVE datset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509cd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriveDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset pour DRIVE :\n",
    "      - img_dir    : .../training/images ou .../test/images\n",
    "      - manual_dir : .../training/1st_manual ou .../test/1st_manual (vessels)\n",
    "      - fov_dir    : .../training/masks ou .../test/masks (FOV disc)\n",
    "      - img_size   : (H, W)\n",
    "      - indices    : sous-ensemble (pour split train/val)\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, manual_dir, fov_dir,\n",
    "                 img_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                 transforms=None,\n",
    "                 indices=None):\n",
    "        self.img_paths = sorted(list(Path(img_dir).glob(\"*.tif\")))\n",
    "        self.manual_dir = Path(manual_dir)\n",
    "        self.fov_dir    = Path(fov_dir)\n",
    "        self.img_size   = img_size  # (H, W)\n",
    "        self.transforms = transforms\n",
    "        self.indices    = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.indices is None:\n",
    "            return len(self.img_paths)\n",
    "        return len(self.indices)\n",
    "\n",
    "    def _get_paths(self, idx):\n",
    "        if self.indices is not None:\n",
    "            idx = self.indices[idx]\n",
    "\n",
    "        img_path = self.img_paths[idx]\n",
    "        base = img_path.stem              # ex: '21_training' ou '01_test'\n",
    "        num  = base.split('_')[0]         # '21' ou '01'\n",
    "\n",
    "        manual_path = self.manual_dir / f\"{num}_manual1.gif\"\n",
    "\n",
    "        # FOV mask : on cherche \"<base>_mask.*\" quel que soit l'ext\n",
    "        candidates = list(self.fov_dir.glob(f\"{base}_mask.*\"))\n",
    "        if len(candidates) == 0:\n",
    "            raise FileNotFoundError(f\"No FOV mask found for {base} in {self.fov_dir}\")\n",
    "        fov_path = candidates[0]\n",
    "\n",
    "        return img_path, manual_path, fov_path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, manual_path, fov_path = self._get_paths(idx)\n",
    "\n",
    "        H, W = self.img_size\n",
    "\n",
    "        # --- Image RGB ---\n",
    "        img = Image.open(img_path).convert(\"RGB\").resize((W, H), Image.BILINEAR)\n",
    "        img_np = np.array(img).astype(np.float32) / 255.0\n",
    "        img_t = torch.from_numpy(img_np).permute(2, 0, 1)   # (3,H,W)\n",
    "\n",
    "        # --- GT vaisseaux (manual1, binaire) ---\n",
    "        gt_img = Image.open(manual_path).convert(\"L\").resize((W, H), Image.NEAREST)\n",
    "        gt_np = np.array(gt_img)\n",
    "\n",
    "        label_np = np.zeros_like(gt_np, dtype=np.int64)\n",
    "        label_np[gt_np > 0] = 1      # 1 = vessel\n",
    "\n",
    "        label_t = torch.from_numpy(label_np).long().unsqueeze(0)  # (1,H,W)\n",
    "\n",
    "        # --- FOV mask (0 / 1) ---\n",
    "        fov_img = Image.open(fov_path).convert(\"L\").resize((W, H), Image.NEAREST)\n",
    "        fov_np = (np.array(fov_img) > 0).astype(np.uint8)\n",
    "        fov_t = torch.from_numpy(fov_np).long().unsqueeze(0)      # (1,H,W)\n",
    "\n",
    "        sample = {\"image\": img_t, \"label\": label_t, \"fov\": fov_t}\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b054b5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices (image numbers): [21, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 36, 37, 38, 39, 40]\n",
      "Val indices (image numbers):   [22, 29, 31, 35]\n",
      "Train / Val / Test sizes: 16 4 20\n"
     ]
    }
   ],
   "source": [
    "# ========= Préparation des indices train / val sur TRAINING (21–40) =========\n",
    "train_img_paths_all = sorted(list(Path(train_images_dir).glob(\"*.tif\")))\n",
    "train_nums = [int(p.stem.split(\"_\")[0]) for p in train_img_paths_all]\n",
    "\n",
    "\"\"\"\n",
    "Validation on 22, 29, 31, 35\n",
    "22 = Côtes d'Armor \n",
    "29 = Finistère\n",
    "31 = Haute-Garonne\n",
    "35 = Ille-et-Vilaine\n",
    "\"\"\"\n",
    "val_nums = {22, 29, 31, 35}\n",
    "val_indices = [i for i, n in enumerate(train_nums) if n in val_nums]\n",
    "train_indices = [i for i, n in enumerate(train_nums) if n not in val_nums]\n",
    "\n",
    "print(\"Train indices (image numbers):\", [train_nums[i] for i in train_indices])\n",
    "print(\"Val indices (image numbers):  \", [train_nums[i] for i in val_indices])\n",
    "\n",
    "# ========= Datasets =========\n",
    "train_ds = DriveDataset(\n",
    "    train_images_dir,\n",
    "    train_manual_dir,\n",
    "    train_fov_dir,\n",
    "    img_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    transforms=train_transforms,\n",
    "    indices=train_indices,\n",
    ")\n",
    "\n",
    "val_ds = DriveDataset(\n",
    "    train_images_dir,\n",
    "    train_manual_dir,\n",
    "    train_fov_dir,\n",
    "    img_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    transforms=val_transforms,\n",
    "    indices=val_indices,\n",
    ")\n",
    "\n",
    "test_ds = DriveDataset(\n",
    "    test_images_dir,\n",
    "    test_manual_dir,\n",
    "    test_fov_dir,\n",
    "    img_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    transforms=val_transforms,\n",
    "    indices=None,\n",
    ")\n",
    "\n",
    "# ========= DataLoaders =========\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"Train / Val / Test sizes:\", len(train_ds), len(val_ds), len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b88a3d",
   "metadata": {},
   "source": [
    "# 4) UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fbd5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MonaiUNet(\n",
    "    spatial_dims=2,                             # UNet in 2D\n",
    "    in_channels=3,                              # images RGB => 3 channels\n",
    "    out_channels=NUM_CLASSES,                   # 2 classes : background + vessels\n",
    "    channels=(64, 128, 256, 512, 1024),         # number of feature channels at each level\n",
    "    strides=(2, 2, 2, 2),                       # 4 steps of downsampling (implicite max-pool 2x2)\n",
    "    kernel_size=3,                              # conv 3x3\n",
    "    up_kernel_size=3,                           # up-conv 3x3\n",
    "    num_res_units=0,                            # no residual units -> simple blocs conv+ReLU\n",
    "    act=\"RELU\",                                 # Use ReLU, defaults is PReLU \n",
    "    norm=\"instance\",                                  # no normalization in the 2015 article\n",
    "    dropout=0.0,                                # No dropout here\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9efeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet initialized on cuda\n"
     ]
    }
   ],
   "source": [
    "print(model.__class__.__name__, \"initialized on\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d54044",
   "metadata": {},
   "source": [
    "# 5) Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3424d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=1e-2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4615b",
   "metadata": {},
   "source": [
    "# 6) Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39998fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=50,   # tous les 50 epochs\n",
    "    gamma=0.5       # LR = LR * 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32275ec7",
   "metadata": {},
   "source": [
    "# 7) Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83d01d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour DRIVE (binaire), on commence sans pondération explicite des classes.\n",
    "# Si besoin, on pourra recalculer des poids plus tard à partir des fréquences de pixels.\n",
    "weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "934b63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceCELoss(\n",
    "    include_background=False,   # on ne compte pas le background dans le Dice\n",
    "    to_onehot_y=True,\n",
    "    softmax=True,\n",
    "    weight=weights,\n",
    "    lambda_dice=1.0,\n",
    "    lambda_ce=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0311e",
   "metadata": {},
   "source": [
    "# 8) History and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8f72bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "#   DICTIONNAIRES STOCRAGE (MEAN ONLY)\n",
    "# ===========================================\n",
    "\n",
    "train_history = {\n",
    "    \"loss\": [],\n",
    "    \"accuracy\":   [],\n",
    "    \"dice\":       [],\n",
    "    \"iou\":        [],\n",
    "    \"precision\":  [],\n",
    "    \"recall\":     [],\n",
    "    \"sensitivity\":[],\n",
    "    \"specificity\":[],\n",
    "    \"auc\":        [],\n",
    "    \"lr\":         [],\n",
    "    \"alpha\":      []\n",
    "}\n",
    "\n",
    "val_history = {\n",
    "    \"loss\": [],\n",
    "    \"accuracy\":   [],\n",
    "    \"dice\":       [],\n",
    "    \"iou\":        [],\n",
    "    \"precision\":  [],\n",
    "    \"recall\":     [],\n",
    "    \"sensitivity\":[],\n",
    "    \"specificity\":[],\n",
    "    \"auc\":        []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb847c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_confmat_sums(num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Agrégats TP/FP/FN/TN sur l'ensemble du dataset.\n",
    "    N = nombre de pixels pris en compte (dans le FOV).\n",
    "    \"\"\"\n",
    "    sums = {\n",
    "        \"TP\": np.zeros(num_classes, dtype=np.int64),\n",
    "        \"FP\": np.zeros(num_classes, dtype=np.int64),\n",
    "        \"FN\": np.zeros(num_classes, dtype=np.int64),\n",
    "        \"TN\": np.zeros(num_classes, dtype=np.int64),\n",
    "        \"N\":  0,\n",
    "    }\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c052a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_auc_buffers(classes):\n",
    "    \"\"\"\n",
    "    Buffers pour stocker y_true / y_score par classe (liste d'indices de classes).\n",
    "    Exemple : classes = [VESSEL_CLASS].\n",
    "    \"\"\"\n",
    "    buffers = {}\n",
    "    for c in classes:\n",
    "        buffers[c] = {\"y_true\": [], \"y_score\": []}\n",
    "    return buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9206c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_confmat_sums(sums, preds, targets, num_classes=NUM_CLASSES, fov=None):\n",
    "    \"\"\"\n",
    "    Met à jour les compteurs TP/FP/FN/TN pour chaque classe.\n",
    "    preds, targets, fov : tensors (N,H,W)\n",
    "    Seuls les pixels avec fov == 1 sont pris en compte (si fov n'est pas None).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        if fov is not None:\n",
    "            f = fov.bool()\n",
    "        else:\n",
    "            f = None\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            p = (preds == c)\n",
    "            t = (targets == c)\n",
    "\n",
    "            if f is not None:\n",
    "                p = p & f\n",
    "                t = t & f\n",
    "\n",
    "            tp = (p & t).sum().item()\n",
    "            fp = (p & ~t).sum().item()\n",
    "            fn = (~p & t).sum().item()\n",
    "            tn = (~p & ~t).sum().item()\n",
    "\n",
    "            sums[\"TP\"][c] += tp\n",
    "            sums[\"FP\"][c] += fp\n",
    "            sums[\"FN\"][c] += fn\n",
    "            sums[\"TN\"][c] += tn\n",
    "\n",
    "        if f is not None:\n",
    "            sums[\"N\"] += f.sum().item()\n",
    "        else:\n",
    "            sums[\"N\"] += targets.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94bffdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_auc_buffers(buffers, logits, targets, fov=None):\n",
    "    \"\"\"\n",
    "    Stocke y_true / y_score pour calculer l'AUC par classe ensuite.\n",
    "    - logits: (N,C,H,W)\n",
    "    - targets: (N,H,W)\n",
    "    - fov: (N,H,W) ou None\n",
    "    Seuls les pixels avec fov == 1 sont pris en compte.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        probs = F.softmax(logits, dim=1)  # (N,C,H,W)\n",
    "\n",
    "        flat_probs = probs.permute(0, 2, 3, 1).reshape(-1, probs.shape[1])\n",
    "        flat_t     = targets.reshape(-1)\n",
    "\n",
    "        if fov is not None:\n",
    "            flat_f = fov.reshape(-1).bool()\n",
    "            flat_probs = flat_probs[flat_f]\n",
    "            flat_t     = flat_t[flat_f]\n",
    "\n",
    "        for c in buffers.keys():\n",
    "            y_true  = (flat_t == c).cpu().numpy().astype(np.uint8)\n",
    "            y_score = flat_probs[:, c].cpu().numpy()\n",
    "            buffers[c][\"y_true\"].append(y_true)\n",
    "            buffers[c][\"y_score\"].append(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4576f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scalar_metrics_from_confmat(sums, include_classes):\n",
    "    \"\"\"\n",
    "    Calcule accuracy / precision / recall / specificity / dice / IoU\n",
    "    en moyenne sur les classes listées (ex: [VESSEL_CLASS]).\n",
    "    \"\"\"\n",
    "    TP, FP, FN, TN = sums[\"TP\"], sums[\"FP\"], sums[\"FN\"], sums[\"TN\"]\n",
    "    eps = 1e-7\n",
    "\n",
    "    acc_c  = (TP + TN) / np.maximum(TP + TN + FP + FN, eps)\n",
    "    prec_c = TP / np.maximum(TP + FP, eps)\n",
    "    rec_c  = TP / np.maximum(TP + FN, eps)\n",
    "    spec_c = TN / np.maximum(TN + FP, eps)\n",
    "    dice_c = (2 * TP) / np.maximum(2 * TP + FP + FN, eps)\n",
    "    iou_c  = TP / np.maximum(TP + FP + FN, eps)\n",
    "\n",
    "    idx = np.array(include_classes, dtype=int)\n",
    "    return {\n",
    "        \"accuracy\":    float(np.mean(acc_c[idx])),\n",
    "        \"precision\":   float(np.mean(prec_c[idx])),\n",
    "        \"recall\":      float(np.mean(rec_c[idx])),\n",
    "        \"specificity\": float(np.mean(spec_c[idx])),\n",
    "        \"dice\":        float(np.mean(dice_c[idx])),\n",
    "        \"iou\":         float(np.mean(iou_c[idx])),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d903ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_auc(buffers):\n",
    "    \"\"\"\n",
    "    Calcule l'AUC moyen en moyennant sur les classes présentes dans `buffers`.\n",
    "    \"\"\"\n",
    "    aucs = []\n",
    "    for c, pack in buffers.items():\n",
    "        if len(pack[\"y_true\"]) == 0:\n",
    "            continue\n",
    "        y_true  = np.concatenate(pack[\"y_true\"])\n",
    "        y_score = np.concatenate(pack[\"y_score\"])\n",
    "\n",
    "        pos = (y_true == 1).sum()\n",
    "        neg = (y_true == 0).sum()\n",
    "        if pos == 0 or neg == 0:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true, y_score))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if len(aucs) == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(np.mean(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df73f0",
   "metadata": {},
   "source": [
    "# 9) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20dece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # =========================\n",
    "    #        TRAIN\n",
    "    # =========================\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    conf_sums = init_confmat_sums()\n",
    "    auc_buf   = init_auc_buffers([VESSEL_CLASS])\n",
    "\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs  = imgs.to(device, non_blocking=True)\n",
    "        masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)  # (N,C,H,W)\n",
    "        loss    = loss_function(outputs, masks)  # Dice + CE (MONAI)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = imgs.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        update_confmat_sums(conf_sums, preds, masks, NUM_CLASSES)\n",
    "        update_auc_buffers(auc_buf, outputs, masks)\n",
    "\n",
    "    train_loss   = running_loss / len(train_ds)\n",
    "    train_metrics = compute_scalar_metrics_from_confmat(conf_sums, VESSEL_CLASSES)\n",
    "    train_auc     = compute_mean_auc(auc_buf)\n",
    "\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    train_history[\"loss\"].append(train_loss)\n",
    "    train_history[\"accuracy\"].append(train_metrics[\"accuracy\"])\n",
    "    train_history[\"dice\"].append(train_metrics[\"dice\"])\n",
    "    train_history[\"iou\"].append(train_metrics[\"iou\"])\n",
    "    train_history[\"precision\"].append(train_metrics[\"precision\"])\n",
    "    train_history[\"recall\"].append(train_metrics[\"recall\"])\n",
    "    train_history[\"specificity\"].append(train_metrics[\"specificity\"])\n",
    "    train_history[\"auc\"].append(train_auc)\n",
    "    train_history[\"lr\"].append(current_lr)\n",
    "\n",
    "    # =========================\n",
    "    #       VALIDATION\n",
    "    # =========================\n",
    "    model.eval()\n",
    "\n",
    "    val_running_loss = 0.0\n",
    "    conf_sums_val = init_confmat_sums()\n",
    "    auc_buf_val   = init_auc_buffers(classes=[VESSEL_CLASS])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs  = imgs.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss    = loss_function(outputs, masks)\n",
    "\n",
    "            batch_size = imgs.size(0)\n",
    "            val_running_loss += loss.item() * batch_size\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            update_confmat_sums(conf_sums_val, preds, masks, NUM_CLASSES)\n",
    "            update_auc_buffers(auc_buf_val, outputs, masks)\n",
    "\n",
    "    val_loss    = val_running_loss / len(val_ds)\n",
    "    val_metrics = compute_scalar_metrics_from_confmat(conf_sums_val, [VESSEL_CLASS])\n",
    "    val_auc     = compute_mean_auc(auc_buf_val)\n",
    "\n",
    "    val_history[\"loss\"].append(val_loss)\n",
    "    val_history[\"accuracy\"].append(val_metrics[\"accuracy\"])\n",
    "    val_history[\"dice\"].append(val_metrics[\"dice\"])\n",
    "    val_history[\"iou\"].append(val_metrics[\"iou\"])\n",
    "    val_history[\"precision\"].append(val_metrics[\"precision\"])\n",
    "    val_history[\"recall\"].append(val_metrics[\"recall\"])\n",
    "    val_history[\"specificity\"].append(val_metrics[\"specificity\"])\n",
    "    val_history[\"auc\"].append(val_auc)\n",
    "\n",
    "    # =========================\n",
    "    #        LOGS\n",
    "    # =========================\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}\")\n",
    "    print(f\"  Train Dice: {train_metrics['dice']:.4f} | Val Dice: {val_metrics['dice']:.4f}\")\n",
    "    print(f\"  Current LR: {current_lr:.6f}\")\n",
    "\n",
    "    # =========================\n",
    "    #   SAVE BEST MODELS\n",
    "    # =========================\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), str(models_dir / \"loss_best_model_state_dict.pth\"))\n",
    "        torch.save(model,              str(models_dir / \"loss_best_model_full.pth\"))\n",
    "        print(\"✅ New best model (loss) saved\")\n",
    "\n",
    "    if val_metrics[\"dice\"] > best_val_dice:\n",
    "        best_val_dice = val_metrics[\"dice\"]\n",
    "        torch.save(model.state_dict(), str(models_dir / \"dice_best_model_state_dict.pth\"))\n",
    "        torch.save(model,              str(models_dir / \"dice_best_model_full.pth\"))\n",
    "        print(\"✅ New best model (dice) saved\")\n",
    "\n",
    "    # =========================\n",
    "    #   SCHEDULER STEP\n",
    "    # =========================\n",
    "    scheduler.step()\n",
    "\n",
    "# =========================\n",
    "#     SAVE LAST MODEL\n",
    "# =========================\n",
    "torch.save(model.state_dict(), str(models_dir / f\"epoch{EPOCHS}_model_state_dict.pth\"))\n",
    "torch.save(model,              str(models_dir / f\"epoch{EPOCHS}_model_full.pth\"))\n",
    "print(\"✅ Last model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802029d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"UNet_train_history.json\", \"w\") as f:\n",
    "    json.dump(train_history, f, indent=4)\n",
    "\n",
    "with open(data_dir / \"UNet_val_history.json\", \"w\") as f:\n",
    "    json.dump(val_history, f, indent=4)\n",
    "\n",
    "print(\"Historiques sauvegardés en JSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a87ca",
   "metadata": {},
   "source": [
    "# 10) Validation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a3964",
   "metadata": {},
   "source": [
    "#### 10.1) Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c929f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(models_dir / \"dice_best_model_state_dict.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447b403",
   "metadata": {},
   "source": [
    "#### 10.2) Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ead5c",
   "metadata": {},
   "source": [
    "#### 10.3) Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf6105",
   "metadata": {},
   "source": [
    "#### 10.3) Table of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d3c36",
   "metadata": {},
   "source": [
    "lol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
